# machine-learning-complete-guide
This repository contains the notebooks from the basic level to the production level of the machine learning process. This helps to understand how to approach the problem and the syntaxes for the data preprocessing. 

# Table of Contents
- Python Classes
  - **Advanced Python:** Decorators, Namespace, Iterators, Iterable and Iteration
  - **Object-oriented programming:** classes, objects, encapsulation, static keywords, inheritance, polymorphism, and abstraction.
- ML Libraries
  - Numpy
  - Pandas
  - Matplotlib
  - Seaborn
- Play With Data
  - Working with CSV
  - Understanding your data
- Exploratory Data Analysis (EDA)
  - EDA with Univariate Analysis
  - EDA with  Bivariate and Multivariate Analysis
- Feature Engineering
  - **Feature Scaling:** Standardization, Normalization, Ordinal and Label Encoder, Nominal Encoding(One Hot Encoding)
  - **Feature Transformation:** Column Transformer, Function Transformer, Power Transformer (Box-Cox, Yeo-Johnson), Binning and Binarization.
  - **Machine Learning Pipelines:** Titanic dataset with and without Pipeline
  - **Handling Missing Values:** Mixed Variable, Date and Time Variable, Complete Case Analysis, Numerical Data, Categorical Data, Random Sample Imputer, Missing Indicator, Auto Select Imputer, KNN Imputer, Iterative Imputation.
  - **Outliers:** Outliers Removal using Z Score, IQR Range, Winsorization
- Feature Construction and Feature Splitting
  - Feature Construction
  - Feature Splitting
- Regression and Gradient Descent
  - Simple Linear Regression
  - Custom Simple Linear Regression
  - Regression Metrics: Mean Absolute Error, Mean Squared Error, Root Mean Squared Error, Adjusted R2 Score
  - Multiple Linear Regression
  - Custom Multiple Linear Regression
  - Gradient Descent Step by Step
  - Custom Function for Gradient Descent
  - Gradient Descent Calculation of Slopes and Intercepts
  - Batch Gradient Descent
  - Stochastic Gradient Descent
  - Mini Batch Gradient Descent
  - Polynomial Regression
  - Ridge Regression
  - Lasso Regression
  - Elastic Net Regression
  - Logistic Regression
  - Classification Metrics: Accuracy, Confusion Matrix, Precision, Recall, F1 Score
  - Softmax Regression
  - Polynomial Logistic Regression
  - Logistic Regression Hyperparameters Tuning
- Decision Trees and Regression Trees
  - Decision Trees
  - Regression Trees
- Ensemble Learning
  - **Voting Ensemble:** Classification and Regression
  - **Bagging Ensemble:** Implementation, Classification and Regression
- Random Forest
  - Random Forest Implementation
  - Bias Variance Trade-Off in Random Forest
  - Bagging vs Random Forest
  - Random Forest Hyper Parameter Tuning
  - Out Of Bag Score [OOB Score]
  - Feature Importance Using Random Forest
- AdaBoost Classifier
  - AdaBoost Algorithm Implementation
  - AdaBoost Hyperparameters [Tuning & Implementing GridSearchCV]
- K-Means Clustering
  - K-Means Clustering using `sklearn or scikit-learn` and Elbow Method


All General Code Snippet: [machine-learning.py](https://github.com/Vishal-sys-code/machine-learning-complete-guide/blob/main/machine-learning.py)

Machine Learning Templates [ReadMe]: [Machine_Learning_Template](https://github.com/Vishal-sys-code/machine-learning-complete-guide/tree/main/Machine%20Learning%20Templates)
